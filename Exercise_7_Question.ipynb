{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EgorBEremeev/SoloLearmML-coursera-deeplearning.ai/blob/master/Exercise_7_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "a185f8e5-e3ee-4f40-c49b-b7f705ce280d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n",
        "                                include_top=False,\n",
        "                                weights=None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-07 08:03:09--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.166.128, 2a00:1450:400c:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.166.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep  21%[===>                ]  18.26M  91.3MB/s               \r        /tmp/incept  76%[==============>     ]  64.52M   161MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   171MB/s    in 0.5s    \n",
            "\n",
            "2019-08-07 08:03:09 (171 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0807 08:03:10.638561 140267317397376 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "1115dc63-6d9d-41b7-c1b0-889c35a006a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed8')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 3, 3, 1280))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "\n",
        "class on_accuracy_reach_callback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, accuracy=0.99):\n",
        "    self.accuracy = accuracy\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>self.accuracy):\n",
        "      print(\"\\nReached {} accuracy so cancelling training!\".format(self.accuracy))\n",
        "      self.model.stop_training = True\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "3219956f-0083-49bd-c7cc-d71c9f6638c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 11520)        0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1024)         11797504    flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            1025        dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 22,473,377\n",
            "Trainable params: 11,798,529\n",
            "Non-trainable params: 10,674,848\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "6e02e497-ca32-4512-ce79-a278a1f56cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-07 08:38:45--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.206.128, 2a00:1450:400c:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.206.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   124MB/s    in 1.2s    \n",
            "\n",
            "2019-08-07 08:38:47 (124 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-08-07 08:38:48--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.133.128, 2a00:1450:400c:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.133.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  43.4MB/s    in 0.3s    \n",
            "\n",
            "2019-08-07 08:38:49 (43.4 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "99d0f077-6b4f-479c-90a1-776a854aa2d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses'\n",
        "train_humans_dir = '/tmp/training/humans'\n",
        "validation_horses_dir = '/tmp/validation/horses'\n",
        "validation_humans_dir = '/tmp/validation/humans'\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "19608a21-65c6-4245-9562-a6502b6f72eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size = (150, 150),\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary' \n",
        "                                                    )     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         target_size = (150, 150),\n",
        "                                                         batch_size = 20,\n",
        "                                                         class_mode = 'binary')\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "c4c03141-e94c-4d79-c8b0-40fc47b90446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "DESIRED_ACCURACY = 0.999\n",
        "callbacks = [on_accuracy_reach_callback(DESIRED_ACCURACY)]\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              epochs=100,\n",
        "                              steps_per_epoch=52,\n",
        "                              validation_steps=50,\n",
        "                              verbose=2,\n",
        "                              callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "52/52 - 21s - loss: 0.3641 - acc: 0.8793 - val_loss: 0.0365 - val_acc: 0.9960\n",
            "Epoch 2/100\n",
            "52/52 - 17s - loss: 0.2228 - acc: 0.9270 - val_loss: 0.0107 - val_acc: 0.9970\n",
            "Epoch 3/100\n",
            "52/52 - 17s - loss: 0.0445 - acc: 0.9864 - val_loss: 0.0098 - val_acc: 0.9960\n",
            "Epoch 4/100\n",
            "52/52 - 17s - loss: 0.0797 - acc: 0.9757 - val_loss: 6.6514e-04 - val_acc: 1.0000\n",
            "Epoch 5/100\n",
            "52/52 - 17s - loss: 0.0706 - acc: 0.9708 - val_loss: 9.1045e-04 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "52/52 - 17s - loss: 0.0610 - acc: 0.9834 - val_loss: 8.8001e-04 - val_acc: 1.0000\n",
            "Epoch 7/100\n",
            "52/52 - 17s - loss: 0.0613 - acc: 0.9796 - val_loss: 0.0300 - val_acc: 0.9838\n",
            "Epoch 8/100\n",
            "52/52 - 17s - loss: 0.0324 - acc: 0.9873 - val_loss: 0.0023 - val_acc: 1.0000\n",
            "Epoch 9/100\n",
            "52/52 - 17s - loss: 0.0268 - acc: 0.9893 - val_loss: 0.0384 - val_acc: 0.9838\n",
            "Epoch 10/100\n",
            "52/52 - 17s - loss: 0.0398 - acc: 0.9883 - val_loss: 2.0134e-04 - val_acc: 1.0000\n",
            "Epoch 11/100\n",
            "52/52 - 17s - loss: 0.0374 - acc: 0.9903 - val_loss: 0.0524 - val_acc: 0.9808\n",
            "Epoch 12/100\n",
            "52/52 - 17s - loss: 0.0489 - acc: 0.9854 - val_loss: 0.0747 - val_acc: 0.9818\n",
            "Epoch 13/100\n",
            "52/52 - 17s - loss: 0.0248 - acc: 0.9893 - val_loss: 0.4153 - val_acc: 0.9443\n",
            "Epoch 14/100\n",
            "52/52 - 17s - loss: 0.0288 - acc: 0.9922 - val_loss: 0.1656 - val_acc: 0.9656\n",
            "Epoch 15/100\n",
            "52/52 - 17s - loss: 0.0741 - acc: 0.9815 - val_loss: 0.0334 - val_acc: 0.9818\n",
            "Epoch 16/100\n",
            "52/52 - 17s - loss: 0.0591 - acc: 0.9825 - val_loss: 0.0601 - val_acc: 0.9808\n",
            "Epoch 17/100\n",
            "52/52 - 17s - loss: 0.0297 - acc: 0.9883 - val_loss: 0.0490 - val_acc: 0.9798\n",
            "Epoch 18/100\n",
            "52/52 - 17s - loss: 0.0258 - acc: 0.9942 - val_loss: 1.1745e-05 - val_acc: 1.0000\n",
            "Epoch 19/100\n",
            "52/52 - 17s - loss: 0.0395 - acc: 0.9873 - val_loss: 0.3340 - val_acc: 0.9534\n",
            "Epoch 20/100\n",
            "52/52 - 17s - loss: 0.0424 - acc: 0.9864 - val_loss: 0.0710 - val_acc: 0.9727\n",
            "Epoch 21/100\n",
            "52/52 - 17s - loss: 0.0260 - acc: 0.9883 - val_loss: 9.2210e-05 - val_acc: 1.0000\n",
            "Epoch 22/100\n",
            "52/52 - 17s - loss: 0.0342 - acc: 0.9873 - val_loss: 0.4759 - val_acc: 0.9453\n",
            "Epoch 23/100\n",
            "52/52 - 17s - loss: 0.0244 - acc: 0.9922 - val_loss: 0.1745 - val_acc: 0.9696\n",
            "Epoch 24/100\n",
            "52/52 - 17s - loss: 0.0281 - acc: 0.9912 - val_loss: 0.1899 - val_acc: 0.9636\n",
            "Epoch 25/100\n",
            "52/52 - 17s - loss: 0.0278 - acc: 0.9922 - val_loss: 0.1953 - val_acc: 0.9727\n",
            "Epoch 26/100\n",
            "52/52 - 17s - loss: 0.0335 - acc: 0.9883 - val_loss: 0.0619 - val_acc: 0.9838\n",
            "Epoch 27/100\n",
            "52/52 - 17s - loss: 0.0226 - acc: 0.9922 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 28/100\n",
            "52/52 - 17s - loss: 0.0248 - acc: 0.9922 - val_loss: 0.2296 - val_acc: 0.9727\n",
            "Epoch 29/100\n",
            "52/52 - 17s - loss: 0.0529 - acc: 0.9883 - val_loss: 6.1603e-07 - val_acc: 1.0000\n",
            "Epoch 30/100\n",
            "52/52 - 17s - loss: 0.0370 - acc: 0.9883 - val_loss: 2.7349e-05 - val_acc: 1.0000\n",
            "Epoch 31/100\n",
            "52/52 - 17s - loss: 0.0266 - acc: 0.9893 - val_loss: 0.2224 - val_acc: 0.9686\n",
            "Epoch 32/100\n",
            "52/52 - 17s - loss: 0.0439 - acc: 0.9893 - val_loss: 0.0980 - val_acc: 0.9868\n",
            "Epoch 33/100\n",
            "52/52 - 17s - loss: 0.0331 - acc: 0.9883 - val_loss: 0.2052 - val_acc: 0.9767\n",
            "Epoch 34/100\n",
            "52/52 - 17s - loss: 0.0336 - acc: 0.9912 - val_loss: 0.0400 - val_acc: 0.9848\n",
            "Epoch 35/100\n",
            "52/52 - 17s - loss: 0.0123 - acc: 0.9951 - val_loss: 0.2540 - val_acc: 0.9656\n",
            "Epoch 36/100\n",
            "52/52 - 17s - loss: 0.0168 - acc: 0.9951 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 37/100\n",
            "52/52 - 17s - loss: 0.0527 - acc: 0.9922 - val_loss: 0.2324 - val_acc: 0.9727\n",
            "Epoch 38/100\n",
            "52/52 - 17s - loss: 0.0277 - acc: 0.9951 - val_loss: 0.0508 - val_acc: 0.9848\n",
            "Epoch 39/100\n",
            "52/52 - 17s - loss: 0.0198 - acc: 0.9942 - val_loss: 0.1476 - val_acc: 0.9808\n",
            "Epoch 40/100\n",
            "52/52 - 17s - loss: 0.0207 - acc: 0.9942 - val_loss: 0.0284 - val_acc: 0.9879\n",
            "Epoch 41/100\n",
            "52/52 - 17s - loss: 0.0347 - acc: 0.9912 - val_loss: 0.6771 - val_acc: 0.9403\n",
            "Epoch 42/100\n",
            "52/52 - 17s - loss: 0.0137 - acc: 0.9961 - val_loss: 0.1471 - val_acc: 0.9777\n",
            "Epoch 43/100\n",
            "52/52 - 17s - loss: 0.0287 - acc: 0.9903 - val_loss: 0.4284 - val_acc: 0.9565\n",
            "Epoch 44/100\n",
            "52/52 - 17s - loss: 0.0406 - acc: 0.9893 - val_loss: 0.0154 - val_acc: 0.9919\n",
            "Epoch 45/100\n",
            "52/52 - 17s - loss: 0.0181 - acc: 0.9961 - val_loss: 0.1716 - val_acc: 0.9777\n",
            "Epoch 46/100\n",
            "52/52 - 17s - loss: 0.0415 - acc: 0.9883 - val_loss: 0.0161 - val_acc: 0.9919\n",
            "Epoch 47/100\n",
            "52/52 - 17s - loss: 0.0174 - acc: 0.9942 - val_loss: 0.0725 - val_acc: 0.9838\n",
            "Epoch 48/100\n",
            "\n",
            "Reached 0.999 accuracy so cancelling training!\n",
            "52/52 - 17s - loss: 0.0052 - acc: 0.9990 - val_loss: 0.0085 - val_acc: 0.9960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "01f8422a-ca20-44ac-dcaa-b3b353da849f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvnPOFcSLvnPOFeQnVkD/4AXZkeQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}